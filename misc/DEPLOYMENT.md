## Design blueprint: Testground Deployments

### Scope

With this document, we aim to explore and answer the following questions:

* how will the testground be deployed in practice?
* the isolation vs. cost dilemma.
* how many environments will exist? with what guarantees / SLAs? when should
  each be used?
* DX: end-to-end development of a new test plan until it's running continuously.
* how production workloads will be muxed onto a shared deployment.
* how PL-specific deployments coexist with our desire to make testground a
  public asset for anyone to use (i.e. platform/cloud-independence), i.e.
  "testground as a service".

Answering these questions is vital to provide clarity to the many groups
collaborating, relying and developing testground, especifically the infra
efforts.

### Daemonising the testground: a pre-requisite

Up until November 2019, testground was operated by ephemeral CLI commands. There
was no long-lived process. Testground was instantiated embedded in every single
command. We were fleshing out the guts of the system, implementing the basic
building blocks and primitives on top of which the rest of the system would
hinge. Our focus was on the plumbing, not on the porcelain. This was by design;
part of a structured SWE process to create a greenfield system.

Testground has now matured significantly, and in order to implement the next set
of features, we need the testground to operate as it was always intended to
operate: as a long-lived daemon. Examples of such features include test run
queueing & scheduling, test run state tracking, and GitHub automation.

Daemonising the testground was already achieved in PR
[#183](https://github.com/ipfs/testground/pull/183). All the deployment modes
described herein rely on testground running as a daemon service.

### Deploying testground

Testground is a project that anyone can take and deploy in their own
infrastructure, whether cloud, on-premise or even in a single-machine. It is not
dependent on any PL-specific pieces of infrastructure. It is
platform/provider-agnostic by design.

That said, at Protocol Labs we're pursue continuous testing of the IPFS and
libp2p projects (first). We thus operate Testground deployment as a service,
watching GitHub, receiving commands, scheduling builds and runs on a fleet of
workers, and tracking and reporting their progress and results via a visual
dashboard (caveat: many of these pieces are WIP as r0 of this doc).

The above entails managing infrastructure and environments. To automate such
tasks, we've chosen a synergistic combination of popular tools:

* *Terraform configurations* to manage the physical infrastructure. These are
  _cloud-specific_. The PL team runs testground on AWS, and we've open sourced
  our configurations.
    * Users on AWS can borrow these configs and take off. Users using other
      providers will need to replace the Terraform configs.
* *Ansible playbooks* to manage the logical infrastructure, such as Docker
  services, system services, overlay networks, etc. The Ansible scripts are
  _cloud-leaky_. In theory they could be cloud-agnostic, but in practice various
  items such as S3 storage, AWS ECR authentication, etc. are cloud-specific.
    * Users wishing to deploy testground on an alternate provider, will need to
      patch those elements.
* _[terraform-inventory](https://github.com/adammck/terraform-inventory)_ for
  the hand-off between the two.

These assets handle the instantiation of various node types of nodes, and the
backing infrastructural elements (e.g. machines, VPCs, security groups, etc.):

1. **Testground manager**: runs the daemon, watches GitHub, exposes an
   authenticated API over HTTPS, serves the dashboard, keeps track of run state,
   schedules incoming runs, governs and scales the worker pool size.
2. **Testground worker**: runs testground workloads.
3. **Testground redis**: a dedicated instance to run the sync service backend
   (Redis).

We think of the deployment generated by these as a _prototype deployment_. We
run multiple replicas of this prototype as specified in the next section.

### Environments

At Protocol Labs, we run multiple deployments of testground to cater for the
IPFS and libp2p projects. We call these "environments".

An environment belongs to one of four classes. Each environment is identified by
a unique name, and this name is used in all its resources for scoping and
identification purposes.

1. **Isolated developer playground:** dedicated entirely to a single developer;
   this is their laboratory. Created and torn down at will. They can make or
   break anything they want here. It will not affect test runs in other
   environments.

     * URL: `dev-<name>.testground.ipfs.team`

     * Availability: Developers don't work 24/7, and neither should their
       playground be powered on 24/7. Doing so would be wasteful. At the same
       time, we don't want to destroy and recreate the environment frequently;
       that takes time, and there's nothing worse than sitting with your arms
       crossed / context switching for 10 minutes before you can start working.

     * Scaling: the scale is determined manually. The developer uses
       Terraform/Ansible to input the initial scale upon instantiation, and to
       scale up and down from there onwards. 
       
       The dev scheduler takes care of automatically shutting down idle workers
       and, ultimately, the Redis instance, keeping the master always alive.
       
       Downscaling will be performed on idle timeout, and upscaling on demand.
       
       Additionally, we'll develop `halt` and `resume` commands for manual
       control.

     * Job scheduling: the developer sets the scheduling policy they wish. 

     * Job sourcing: playgrounds are not connected to GitHub, and hence they
       perform no automated jobs. All jobs are scheduled manually via the CLI.

     * Updating: the developer updates `testground` manually.

2. **Production testground (url: `prd.testground.ipfs.team`):** serves the IPFS
   and libp2p projects and communities.
   
     * URL: `prd.testground.ipfs.team`

     * Availability: 24/7.

     * Scaling: dynamically set by the scheduler, within bounds. Workers are
       spawned and stopped based on the capacity calculations performed by the
       scheduler.
   
     * Job scheduling: parallel execution. For runs, the concurrency is dynamic
       and determined by the scheduler and the scale of the jobs in progress. It
       uses a bin-packing algorithm to make capacity and scaling decisions. For
       builds, the concurrency level is capped.
  
     * Job sourcing: GitHub automation + authenticated manual API calls.

     * Updating: updated manually after changes are verified in staging.

3. **Staging testground:** CI environment for testground itself. It runs
   `master`, duplicating all jobs from production. The goal is to certify
   changes on `master`.

   * URL: `stg.testground.ipfs.team`

   * Availability: 24/7.

   * Scaling: same as production.
   
   * Job scheduling: same as production.
  
   * Job sourcing: cloned from production (can do this by duplicating API
     calls, i.e. 100% canary).

   * Updating: updated continuously as `master` moves.

4. **Shared experimental testground (ns: `exp`):** the first shared test
   environment where test jobs from various developers converge. Developers will
   use this environment to run jobs at scale, and to get a feel for how their
   test plan will behave in production, without polluting the latter. It closely
   follows

     * URL: `exp.testground.ipfs.team`

     * Availability: same as dev environments -- on-demand.
   
     * Scaling: same as production.

     * Job scheduling: same as production.

     * Job sourcing: authenticated manual API calls.

     * Updating: follows production.

### End-to-end developer experience

WIP. Cycling through environments.

### Scheduler/scaler component

WIP.

### Updating testground

WIP.

###Â Authentication

WIP.



